# ğŸ† Agents League â€” Live Demo Guide

> **Agents League Battle #2 Â· Certification Prep Multi-Agent System**  
> A complete end-to-end walkthrough of all demo scenarios, agent outputs, and the Admin Dashboard.  
> Built for judges, evaluators, and curious engineers.

---

## Table of Contents

1. [Quick Access](#quick-access)
2. [Application Overview](#application-overview)
3. [How to Run a Demo](#how-to-run-a-demo)
4. [Scenario 1 â€” AI Beginner (Alex Chen, AI-102)](#scenario-1--ai-beginner-alex-chen-ai-102)
5. [Scenario 2 â€” Data Professional (Priyanka Sharma, DP-100)](#scenario-2--data-professional-priyanka-sharma-dp-100)
6. [Admin Dashboard Walkthrough](#admin-dashboard-walkthrough)
7. [Learning Tabs Deep-Dive](#learning-tabs-deep-dive)
8. [Responsible AI Guardrails in Action](#responsible-ai-guardrails-in-action)
9. [Architecture at a Glance](#architecture-at-a-glance)
10. [Judging Criteria Checklist](#judging-criteria-checklist)

---

## Quick Access

| Resource | Link |
|----------|------|
| **Live app** | [agentsleague.streamlit.app](https://agentsleague.streamlit.app) |
| **GitHub repo** | [athiq-ahmed/agentsleague](https://github.com/athiq-ahmed/agentsleague) |
| **Local run** | `python -m streamlit run streamlit_app.py` |

**Credentials**

| Role | Username | Password / PIN |
|------|----------|--------------|
| Demo student | *(any name)* | `1234` |
| Admin | `admin` | `agents2026` |

---

## Application Overview

The **Cert Prep Multi-Agent System** turns a 10-minute intake form into a complete, personalised certification study plan. Eight specialised AI agents collaborate in a typed sequential pipeline:

```
Intake Agent
  â””â”€â”€â–º Safety Guardrails
         â””â”€â”€â–º Learner Profiling Agent
                â”œâ”€â”€â–º Study Plan Agent  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â””â”€â”€â–º Learning Path Curator                               â”‚
                       â””â”€â”€â–º Domain Confidence Scorer                    â”‚
                              â””â”€â”€â–º Readiness Gate                        â”‚
                                     â”œâ”€â”€ PASS (â‰¥70%) â†’ Cert Recommender â”¤
                                     â””â”€â”€ FAIL (<70%) â†’ Remediation loop â”˜
```

All agents run in **mock mode by default** â€” zero Azure OpenAI cost, instant sub-second response. Switch to live mode via `src/cert_prep/config.py â†’ USE_MOCK = False`.

![Application home screen â€” intake form](screenshots/01_home_intake_form.png)
*Caption: Home screen showing the two-column intake form, demo scenario buttons in the sidebar, and the Agents League branding.*

---

## How to Run a Demo

### Option A â€” One-Click Scenario (recommended for live demos)

1. Open the app at `http://localhost:8501` (or the Streamlit Cloud URL)
2. Enter **any name** and PIN `1234` on the login screen
3. In the **left sidebar**, click one of the two scenario buttons:
   - ğŸŒ± **AI Beginner Â· AI-102** â€” loads Alex Chen's profile
   - ğŸ“Š **Data Professional Â· DP-100** â€” loads Priyanka Sharma's profile
4. Review the pre-filled form, then click **ğŸš€ Generate My Study Plan**
5. The seven output tabs appear instantly

### Option B â€” Custom Profile

1. Fill the intake form manually with any background, exam target, hours per week, and concern topics
2. Click **ğŸš€ Generate My Study Plan**

### Resetting Between Demos

Click **â†© Reset scenario** in the sidebar at any time to clear all state and start fresh.

---

## Scenario 1 â€” AI Beginner (Alex Chen, AI-102)

**Persona:** Recent CS graduate, no cloud or Azure experience, 12 hours/week available over 10 weeks, wants to break into AI engineering.

### Step 1 â€” Load the Scenario

Click **ğŸŒ± AI Beginner Â· AI-102** in the sidebar. The form fills automatically:

| Field | Value |
|-------|-------|
| Name | Alex Chen |
| Exam | AI-102 â€“ Azure AI Engineer Associate |
| Background | Recent CS graduate, basic Python, no cloud experience |
| Prior certs | *(none)* |
| Hours / week | 12 |
| Study weeks | 10 |
| Concern topics | Azure Cognitive Services, Azure OpenAI, Bot Service |
| Learning style | Hands-on labs + Practice tests |
| Goal | Break into AI engineering as a first job |
| Motivation | Career growth |

![Alex Chen scenario â€” pre-filled intake form](screenshots/02_alex_prefill_form.png)
*Caption: Intake form pre-filled for Alex Chen. All fields populated from the sidebar scenario button.*

### Step 2 â€” Generate the Profile

Click **ğŸš€ Generate My Study Plan**. All eight agents run in under a second (mock mode).

![Profile generation loading](screenshots/03_alex_generating.png)
*Caption: Spinner shown while agents run. In mock mode this resolves in <1 second.*

### Step 3 â€” Domain Map (Tab 1)

The **Domain Map** tab shows Alex's readiness across all AI-102 exam domains as a coloured radar chart + sortable table:

- ğŸ”´ **Red** domains (< 40% confidence) â€” highest priority gaps
- ğŸŸ  **Orange** domains (40â€“64%) â€” needs work
- ğŸŸ¢ **Green** domains (â‰¥ 65%) â€” solid, can skim

**Expected output for Alex (beginner):** Nearly all domains in red/orange â€” the system correctly identifies a comprehensive study need with no skip recommendations.

![Alex â€” Domain Map radar chart](screenshots/04_alex_domain_map.png)
*Caption: Domain Map for Alex Chen. Red-dominant radar confirms beginner status. No domains are skip-recommended.*

### Step 4 â€” Study Setup (Tab 2)

Shows the parsed study schedule:

- **Total available hours** = 12 h/week Ã— 10 weeks = **120 hours**
- Hours broken down by domain priority
- Warning displayed if total hours appear insufficient for the exam

![Alex â€” Study Setup hours breakdown](screenshots/05_alex_study_setup.png)
*Caption: Study Setup tab showing 120 total hours distributed across AI-102 domains based on confidence scores.*

### Step 5 â€” Learning Path (Tab 3)

The **Learning Path** tab shows a week-by-week curated curriculum with:
- Microsoft Learn modules linked per domain
- Estimated time per module
- Prerequisites flagged where applicable

**For Alex:** A 10-week full curriculum starting from Azure fundamentals before advancing to Cognitive Services and OpenAI.

![Alex â€” Learning Path weekly plan](screenshots/06_alex_learning_path.png)
*Caption: Learning Path for Alex Chen â€” week-by-week breakdown with module links.*

### Step 6 â€” Recommendations (Tab 4)

The **Cert Recommendation** agent outputs:

- Exam readiness indicator
- Pre-study recommendations (e.g., "Complete AZ-900 first")
- Risk domains that need the most attention
- Whether the learner is on a GO or REMEDIATION path

**For Alex:** System will recommend completing AZ-900 fundamentals as optional prep, and flag generative AI + responsible AI as risk domains.

![Alex â€” Recommendations panel](screenshots/07_alex_recommendations.png)
*Caption: Recommendations panel showing readiness indicator, risk domains, and suggested pre-study steps.*

### Step 7 â€” My Progress (Tab 5)

First visit shows a **Progress Check-In** form (HITL gate 1) â€” the learner self-reports hours studied and confidence. Submit to unlock the full progress analytics.

![Alex â€” Progress Check-In form](screenshots/08_alex_progress_gate.png)
*Caption: Human-in-the-loop gate 1 â€” learner submits self-reported progress before analytics unlock.*

### Step 8 â€” Knowledge Check (Tab 6)

Select a domain from the dropdown and click **ğŸ¯ Start Quiz**. A 5-question adaptive quiz runs. Score â‰¥ 70% â†’ **GO** badge. Score < 70% â†’ **REMEDIATE** badge with weak areas highlighted.

![Alex â€” Knowledge Check quiz in progress](screenshots/09_alex_quiz.png)
*Caption: Knowledge Check tab showing a 5-question quiz for the Azure OpenAI domain.*

![Alex â€” Quiz result with score < 70%](screenshots/10_alex_quiz_fail.png)
*Caption: Readiness Gate result for Alex â€” score below 70% triggers the REMEDIATION path with targeted review links.*

---

## Scenario 2 â€” Data Professional (Priyanka Sharma, DP-100)

**Persona:** 5-year data analyst, experienced in scikit-learn and Azure ML. Holds AZ-900 + AI-900. Targeting DP-100 in 6 weeks at 8 hrs/week. Goal: move into Azure ML Engineer role.

### Step 1 â€” Load the Scenario

Click **ğŸ“Š Data Professional Â· DP-100** in the sidebar.

| Field | Value |
|-------|-------|
| Name | Priyanka Sharma |
| Exam | DP-100 â€“ Azure Data Scientist Associate |
| Background | 5 yrs data analytics, Python, scikit-learn, Azure ML experiments |
| Prior certs | AZ-900, AI-900 |
| Hours / week | 8 |
| Study weeks | 6 |
| Concern topics | Hyperparameter tuning, model deployment, MLflow, data drift |
| Learning style | Video tutorials + Hands-on labs |
| Goal | Earn DP-100 for Azure ML Engineer role switch |
| Motivation | Role switch + Career growth |

![Priyanka â€” pre-filled intake form](screenshots/11_priyanka_prefill_form.png)
*Caption: Intake form pre-filled for Priyanka Sharma. Prior cert field shows AZ-900, AI-900.*

### Step 2 â€” Contrasting Domain Map

With an existing Python + Azure ML background, Priyanka's Domain Map looks starkly different from Alex's:

- Several domains in **green** (skip-recommended)
- Only concern areas (MLflow, data drift, deployment) remain orange/red
- Agent correctly detects prior certs and applies credit

**Key differentiator to highlight in the demo:** Same system, completely different output â€” the agents correctly personalise based on experience level.

![Priyanka â€” Domain Map â€” mostly green with targeted gaps](screenshots/12_priyanka_domain_map.png)
*Caption: Domain Map for Priyanka â€” mostly green with targeted gaps in MLflow and model monitoring. Green domains are skip-recommended.*

### Step 3 â€” Compressed Study Plan

- **Total hours** = 8 Ã— 6 = 48 hours â€” focused, not exhaustive
- Skip-recommended domains free up hours for weak areas
- Study plan is materially shorter and more targeted than Alex's

![Priyanka â€” Study Setup â€” 48-hour compressed plan](screenshots/13_priyanka_study_setup.png)
*Caption: Study Setup for Priyanka â€” 48 hours distributed across only non-skip domains.*

### Step 4 â€” Cert Recommendation: GO Path

Because Priyanka holds prior certs and has strong fundamentals, the Readiness Gate score is typically above 70% â€” she is placed on the **GO** path immediately.

![Priyanka â€” Readiness Gate passes â€” GO badge](screenshots/14_priyanka_go_path.png)
*Caption: Readiness Gate result for Priyanka â€” GO path badge with cert booking recommendation.*

### Step 5 â€” Side-by-Side Comparison

| Dimension | Alex Chen (Beginner) | Priyanka Sharma (Expert) |
|-----------|---------------------|--------------------------|
| Study hours | 120 hrs | 48 hrs |
| Skip-recommended domains | 0 | 3â€“4 |
| Risk domains | 5â€“6 | 1â€“2 |
| Readiness path | REMEDIATE | GO |
| Pre-study suggestion | AZ-900 prep | None |
| Quiz pass rate (demo) | ~55% | ~82% |

This contrast is the **core showpiece** of the multi-agent personalisation.

---

## Admin Dashboard Walkthrough

Access: click **ğŸ” Admin Dashboard** in the sidebar (admin users only).  
Credentials: username `admin`, password `agents2026`.

### Run Summary

Six metric cards showing Run ID, Student, Exam Target, Timestamp, Mode (mock/live), and Total execution time:

![Admin â€” Run Summary cards](screenshots/15_admin_run_summary.png)
*Caption: Run Summary section â€” 6 uniform metric cards showing the profiling run metadata.*

### Agent Execution Timeline (Gantt Chart)

A horizontal Gantt chart showing each agent's start time and duration in milliseconds. In mock mode all bars are tiny (< 50 ms each). In live Azure OpenAI mode, Profiler and Domain Scorer bars grow to 3â€“5 seconds each.

![Admin â€” Gantt chart agent timeline](screenshots/16_admin_gantt.png)
*Caption: Agent Execution Timeline Gantt â€” 6 agents shown with colour-coded bars by agent type.*

### Per-Agent Interaction Log

Every agent card shows:
- **Agent name + colour band** with status badge (success / warning)
- **ğŸ“¨ Input** â€” what data the agent received
- **ğŸ“¤ Output** â€” what the agent produced
- **âš™ï¸ Rules / Decisions Applied** â€” the guardrail rule IDs that fired

![Admin â€” Per-Agent card for Learner Profiling Agent](screenshots/17_admin_agent_card_profiler.png)
*Caption: Per-Agent card for Learner Profiling Agent â€” input received from Intake Agent, output LearnerProfile with confidence scores.*

![Admin â€” Per-Agent card for Domain Confidence Scorer](screenshots/18_admin_agent_card_scorer.png)
*Caption: Domain Confidence Scorer card showing per-domain scores and rules applied.*

![Admin â€” Per-Agent card for Readiness Gate](screenshots/19_admin_agent_card_gate.png)
*Caption: Readiness Gate card â€” decisions section shows the exact threshold rule used (â‰¥ 70% = GO).*

### Domain Decision Audit Trail

A Plotly colour-coded table + horizontal bar chart showing the final per-domain outcome: confidence score, knowledge level, skip recommendation, and risk flag.

![Admin â€” Domain Decision Audit Trail table and bar chart](screenshots/20_admin_audit_trail.png)
*Caption: Domain Decision Audit Trail â€” colour-coded by confidence band. Red = high priority, green = ready.*

### Session History

A full dataframe of all profiling runs in the current browser session, including student name, exam, mode, and average confidence.

![Admin â€” Session History table](screenshots/21_admin_session_history.png)
*Caption: Session History table â€” shows all runs generated in this session with key metrics.*

---

## Learning Tabs Deep-Dive

After generating a profile, seven output tabs appear across the top of the page:

| Tab | What it shows | Key agent |
|-----|--------------|-----------|
| **1 Â· Domain Map** | Radar + bar chart of per-domain confidence | Domain Confidence Scorer |
| **2 Â· Study Setup** | Hours available, domain hour allocation, prereq warning | Study Plan Agent |
| **3 Â· Learning Path** | Week-by-week curated Microsoft Learn modules | Learning Path Curator |
| **4 Â· Recommendations** | Readiness verdict, cert booking guidance, risk domains | Cert Recommendation Agent |
| **5 Â· My Progress** | HITL check-in gate 1 + progress bar analytics | Progress Agent |
| **6 Â· Knowledge Check** | 5-question adaptive quiz + PASS/REMEDIATE gate | Assessment Agent |
| **7 Â· Raw Data** | Full JSON payloads for all agent I/O â€” for debugging | All agents |

Each tab has a **â†‘ Back to top** anchor and a one-liner purpose caption.

---

## Responsible AI Guardrails in Action

The `GuardrailsPipeline` runs **at every agent transition** â€” 17 rules across 6 categories:

| Category | Rules | Effect |
|----------|-------|--------|
| PII Detection | Names/emails in background text | WARN â€” flags detected PII |
| Content Safety | Hateful, harmful, or off-topic text | BLOCK â€” pipeline halts |
| Data Validation | Missing required fields | BLOCK |
| Confidence Bounds | Scores outside 0â€“1 range | BLOCK |
| Scope Guard | Non-Microsoft exam targets | WARN |
| Session Integrity | Tampered or missing session state | BLOCK |

**Demo tip:** On the intake form, try typing `sarah@email.com` in the background field. The guardrail fires a PII warning badge visible in Tab 7 (Raw Data) and in the Admin Dashboard per-agent card for the Intake Agent.

---

## Architecture at a Glance

```
streamlit_app.py (UI Layer)
â”‚
â”œâ”€â”€ src/cert_prep/
â”‚   â”œâ”€â”€ b0_intake_agent.py          Intake + PII check
â”‚   â”œâ”€â”€ guardrails.py               17-rule cross-cutting middleware
â”‚   â”œâ”€â”€ b1_mock_profiler.py         Learner Profiling Agent
â”‚   â”œâ”€â”€ b1_1_learning_path_curator.py  Learning Path Curator Agent
â”‚   â”œâ”€â”€ b1_1_study_plan_agent.py    Study Plan Agent
â”‚   â”œâ”€â”€ b1_2_progress_agent.py      Progress Tracking Agent
â”‚   â”œâ”€â”€ b2_assessment_agent.py      Knowledge Check + Readiness Gate
â”‚   â”œâ”€â”€ b3_cert_recommendation_agent.py  Cert Recommendation Agent
â”‚   â”œâ”€â”€ agent_trace.py              RunTrace / AgentStep telemetry models
â”‚   â”œâ”€â”€ models.py                   Pydantic data contracts
â”‚   â”œâ”€â”€ config.py                   USE_MOCK flag, Azure credentials
â”‚   â””â”€â”€ database.py                 SQLite student registry
â”‚
â””â”€â”€ pages/
    â””â”€â”€ 1_Admin_Dashboard.py        Admin-only agent interaction inspector
```

**Data contracts (Pydantic):**  
`RawStudentInput` â†’ `LearnerProfile` â†’ `StudyPlan` / `LearningPath` â†’ `ReadinessAssessment` â†’ `CertRecommendation`

Every agent receives and returns a typed Pydantic model â€” no raw-string hand-offs, no hallucination-prone free-form dictionaries.

---

## Judging Criteria Checklist

| Criterion | Evidence |
|-----------|---------|
| âœ… Multi-agent orchestration | 6 specialised agents, typed sequential pipeline |
| âœ… Agent handoffs | Pydantic contract at every boundary |
| âœ… Human-in-the-Loop | HITL gate 1 (Progress Check-In) + HITL gate 2 (Quiz submit) |
| âœ… Conditional routing | Readiness Gate: GO vs REMEDIATE path |
| âœ… Responsible AI | 17 guardrail rules, BLOCK/WARN/INFO levels |
| âœ… Explainability | Full per-agent trace in Admin Dashboard |
| âœ… Production quality | Pydantic models, error handling, session management |
| âœ… Personalisation | Identical system â†’ completely different plans for Alex vs Priyanka |
| âœ… No-cost demo mode | All scenarios run without Azure credentials |
| âœ… Real-time UI | Streamlit app with plotly charts, gantt, radar, tables |

---

> **Screenshots:** All `docs/screenshots/*.png` files should be captured from a live demo session.  
> Run the app locally, execute both scenarios, and save screenshots using the filenames referenced above.  
> The Admin Dashboard screenshots require signing in as `admin` / `agents2026` and clicking through after running a scenario first.

---

*Last updated: February 2026 Â· Agents League Battle #2*
